{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f02788a-8174-4428-ae9a-662098a4a024",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a43fdf146b194591848d131211b7055b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:157: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\User\\.cache\\huggingface\\hub\\models--bert-base-uncased. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\User\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61ca537229c7496eb7d2a1cc63918946",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "868b8a6f8f2d48b2a44ef9dd23e381f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31d307a2e5b144f286ed15b44a54b256",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b3ddf4a5b1045b48485c95e42eaf682",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3668 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79d49382e138435d9b964fb82a25b95f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/408 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4344c34bfcbe4dcc88f399d67185923c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1725 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, DataCollatorWithPadding\n",
    "\n",
    "raw_datasets = load_dataset(\"glue\", \"mrpc\")\n",
    "checkpoint = \"bert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "\n",
    "\n",
    "def tokenize_function(example):\n",
    "    return tokenizer(example[\"sentence1\"], example[\"sentence2\"], truncation=True)\n",
    "\n",
    "\n",
    "tokenized_datasets = raw_datasets.map(tokenize_function, batched=True)\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04f2f626-33d3-4b0a-a1b4-218e5fa36eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "training_args = TrainingArguments(\"test-trainer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b61c6ddd-f5dc-44ce-b902-20260786b487",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85d8c21ebdcb48c6a8dae34953e3b970",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f6d8849-d20a-4f73-9ae0-bbb434201235",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer\n",
    "trainer = Trainer(\n",
    "    model,\n",
    "    training_args,\n",
    "    train_dataset = tokenized_datasets[\"train\"],\n",
    "    eval_dataset = tokenized_datasets[\"validation\"],\n",
    "    data_collator = data_collator,\n",
    "    tokenizer = tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8dfa37ab-b7db-4b4f-883f-ad375e9c61e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:435: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at ..\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:455.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1377' max='1377' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1377/1377 02:02, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.502400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.275500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1377, training_loss=0.3179719906919835, metrics={'train_runtime': 123.7155, 'train_samples_per_second': 88.946, 'train_steps_per_second': 11.13, 'total_flos': 405114969714960.0, 'train_loss': 0.3179719906919835, 'epoch': 3.0})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0032794d-d7cb-4678-87df-ea4b70a2b57e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(408, 2) (408,)\n",
      "[[-3.7786803   3.2362819 ]\n",
      " [ 3.2584288  -2.6263905 ]\n",
      " [ 1.674777   -1.0399925 ]\n",
      " [-3.8243372   3.2714367 ]\n",
      " [ 2.765249   -2.1202352 ]\n",
      " [-3.7535908   3.2286727 ]\n",
      " [-3.6924222   3.167512  ]\n",
      " [-3.8677955   3.318034  ]\n",
      " [-3.708501    3.1671546 ]\n",
      " [-3.8080177   3.24639   ]\n",
      " [-3.8637123   3.3223882 ]\n",
      " [ 3.1851928  -2.5798717 ]\n",
      " [ 3.5699568  -2.8527176 ]\n",
      " [-3.7752988   3.22094   ]\n",
      " [-3.8836274   3.3177032 ]\n",
      " [ 3.0007093  -2.2493417 ]\n",
      " [-3.9043114   3.3506255 ]\n",
      " [ 3.1559184  -2.6249375 ]\n",
      " [-3.9050725   3.3512564 ]\n",
      " [ 2.6343267  -1.8383982 ]\n",
      " [ 3.1348684  -2.5518591 ]\n",
      " [-2.124333    1.511873  ]\n",
      " [ 2.9331794  -2.359104  ]\n",
      " [-3.8007708   3.2812412 ]\n",
      " [-3.8769336   3.3202677 ]\n",
      " [ 0.32411978 -0.04353369]\n",
      " [-3.2727222   2.7303233 ]\n",
      " [-3.8877792   3.3340206 ]\n",
      " [-3.7160182   3.2072048 ]\n",
      " [-3.8515077   3.3155713 ]\n",
      " [-0.9120052   0.678909  ]\n",
      " [-3.8925688   3.331471  ]\n",
      " [-3.4792688   2.8983204 ]\n",
      " [-3.8385348   3.2867157 ]\n",
      " [-3.8444712   3.2985482 ]\n",
      " [-3.7566388   3.2441218 ]\n",
      " [ 3.4304955  -2.7229345 ]\n",
      " [ 3.2948878  -2.5735202 ]\n",
      " [-3.016046    2.394018  ]\n",
      " [-3.8888862   3.3317795 ]\n",
      " [ 3.3882542  -2.804499  ]\n",
      " [-3.7155359   3.174116  ]\n",
      " [ 2.7333057  -2.2774572 ]\n",
      " [ 3.1919045  -2.605343  ]\n",
      " [ 0.09580351  0.10749105]\n",
      " [-3.812563    3.2800074 ]\n",
      " [-3.8599968   3.2941396 ]\n",
      " [ 3.2713647  -2.6639857 ]\n",
      " [-3.8755124   3.3367805 ]\n",
      " [-3.8240097   3.3026655 ]\n",
      " [-3.7005608   3.2088888 ]\n",
      " [-3.7792647   3.2623858 ]\n",
      " [-3.7541156   3.2431822 ]\n",
      " [-3.7738087   3.2481408 ]\n",
      " [-3.8743439   3.3115547 ]\n",
      " [-3.2513454   2.7376428 ]\n",
      " [-3.0704186   2.5026042 ]\n",
      " [-3.8170507   3.263771  ]\n",
      " [-3.829646    3.2774224 ]\n",
      " [-3.7264392   3.1786175 ]\n",
      " [ 2.5244682  -1.7041812 ]\n",
      " [ 2.284331   -1.7443619 ]\n",
      " [-3.8176467   3.2683098 ]\n",
      " [-2.5616858   1.9501909 ]\n",
      " [-3.7595809   3.2180076 ]\n",
      " [ 3.1567135  -2.4919908 ]\n",
      " [-3.9212692   3.3480008 ]\n",
      " [-3.8237903   3.2919672 ]\n",
      " [ 2.4555383  -1.8947692 ]\n",
      " [-3.9030552   3.3461885 ]\n",
      " [-3.8478577   3.2839308 ]\n",
      " [-1.891039    1.508142  ]\n",
      " [-3.846287    3.290459  ]\n",
      " [-3.6434681   3.0958712 ]\n",
      " [-3.6479383   3.1267748 ]\n",
      " [-3.7266662   3.2312157 ]\n",
      " [-3.4698536   2.97138   ]\n",
      " [-3.8851361   3.3209336 ]\n",
      " [-3.7223403   3.1865656 ]\n",
      " [-3.8158858   3.2703698 ]\n",
      " [-3.5698614   3.0449553 ]\n",
      " [-3.8432856   3.3079436 ]\n",
      " [-3.8728573   3.3308737 ]\n",
      " [ 2.916257   -2.3174777 ]\n",
      " [-3.809943    3.282274  ]\n",
      " [ 2.4211679  -1.7072924 ]\n",
      " [-3.8072996   3.3069756 ]\n",
      " [-2.7261283   2.1519215 ]\n",
      " [-3.7400985   3.1804662 ]\n",
      " [-3.8861396   3.338339  ]\n",
      " [ 2.020357   -1.4211559 ]\n",
      " [-3.8324301   3.2704787 ]\n",
      " [-3.8084881   3.2865689 ]\n",
      " [-3.173628    2.7026203 ]\n",
      " [-3.9026809   3.3473682 ]\n",
      " [-3.8795016   3.331175  ]\n",
      " [ 1.6939236  -1.0813489 ]\n",
      " [-3.657425    3.1796155 ]\n",
      " [-3.8489552   3.318822  ]\n",
      " [-3.7986445   3.2580872 ]\n",
      " [-3.846394    3.2982311 ]\n",
      " [-3.3515081   2.8348594 ]\n",
      " [-3.815265    3.261945  ]\n",
      " [-3.7939713   3.2665231 ]\n",
      " [-3.550177    3.0308852 ]\n",
      " [-3.8718219   3.312685  ]\n",
      " [-3.751804    3.2593162 ]\n",
      " [ 3.2674809  -2.6677618 ]\n",
      " [ 1.1522709  -0.59940386]\n",
      " [-3.8806806   3.305647  ]\n",
      " [-2.0129616   1.6178497 ]\n",
      " [-3.6322453   3.153401  ]\n",
      " [ 1.2594876  -0.7898199 ]\n",
      " [-3.8582463   3.3069365 ]\n",
      " [-3.4479108   2.9731884 ]\n",
      " [ 3.2712662  -2.6221783 ]\n",
      " [-3.8648877   3.3256614 ]\n",
      " [-3.7220697   3.1772628 ]\n",
      " [-3.8538723   3.3327916 ]\n",
      " [-3.8339758   3.2859957 ]\n",
      " [-3.776452    3.2435944 ]\n",
      " [-3.2602704   2.7294865 ]\n",
      " [ 2.9853013  -2.3749003 ]\n",
      " [-3.8416102   3.30577   ]\n",
      " [-3.8585336   3.299745  ]\n",
      " [-3.8718712   3.3383954 ]\n",
      " [-3.8011746   3.2668576 ]\n",
      " [ 3.0330355  -2.552278  ]\n",
      " [-3.914677    3.353864  ]\n",
      " [-3.8263376   3.286803  ]\n",
      " [-3.5646622   3.016189  ]\n",
      " [ 2.7911985  -2.1909034 ]\n",
      " [-3.632178    3.1330073 ]\n",
      " [-2.697547    2.0451896 ]\n",
      " [-3.6673186   3.2059646 ]\n",
      " [-3.826762    3.2999063 ]\n",
      " [ 3.0566883  -2.3894365 ]\n",
      " [ 3.4746244  -2.771081  ]\n",
      " [-3.8623326   3.314362  ]\n",
      " [-3.761964    3.2418807 ]\n",
      " [-3.8949945   3.345856  ]\n",
      " [ 1.7392142  -1.1421378 ]\n",
      " [ 3.1655552  -2.5974045 ]\n",
      " [-0.9994015   1.0663471 ]\n",
      " [ 2.7450752  -1.8832785 ]\n",
      " [-2.548925    1.9296862 ]\n",
      " [-3.9152808   3.3639064 ]\n",
      " [ 2.3656793  -1.6909369 ]\n",
      " [ 2.8297625  -2.1768801 ]\n",
      " [-3.6211388   3.0677161 ]\n",
      " [ 3.2693324  -2.5937424 ]\n",
      " [-3.8608072   3.3134995 ]\n",
      " [ 2.0258896  -1.4709988 ]\n",
      " [-3.897658    3.3376548 ]\n",
      " [-2.3774257   1.748361  ]\n",
      " [-3.815832    3.2791212 ]\n",
      " [-3.8117032   3.2832482 ]\n",
      " [-3.5288393   3.0781949 ]\n",
      " [ 2.8387141  -2.058802  ]\n",
      " [-3.6810362   3.1513493 ]\n",
      " [-3.7289855   3.217941  ]\n",
      " [-3.791236    3.2754138 ]\n",
      " [-3.8853335   3.319432  ]\n",
      " [-3.8053558   3.2502618 ]\n",
      " [-3.6971645   3.151395  ]\n",
      " [-3.4810853   2.9673629 ]\n",
      " [-3.3488643   2.7915347 ]\n",
      " [ 2.6523228  -2.2300603 ]\n",
      " [-3.7546554   3.2243936 ]\n",
      " [ 3.3185632  -2.690166  ]\n",
      " [ 2.9394345  -2.2929611 ]\n",
      " [ 2.4728227  -1.869233  ]\n",
      " [-3.0709167   2.4818695 ]\n",
      " [-3.686885    3.147222  ]\n",
      " [ 1.9401083  -1.2207078 ]\n",
      " [-3.7945027   3.2850728 ]\n",
      " [-3.8336337   3.2798584 ]\n",
      " [ 3.0819561  -2.4560912 ]\n",
      " [-3.7903388   3.249664  ]\n",
      " [-3.8495271   3.3036551 ]\n",
      " [-2.2103722   1.5389395 ]\n",
      " [-3.4114883   2.8308556 ]\n",
      " [-3.7738156   3.2619734 ]\n",
      " [-3.8431876   3.3037598 ]\n",
      " [ 1.3553704  -0.8229177 ]\n",
      " [-3.0745337   2.598271  ]\n",
      " [ 2.5835078  -2.0289907 ]\n",
      " [ 1.1015856  -0.551005  ]\n",
      " [ 3.0815022  -2.5757644 ]\n",
      " [-3.7296808   3.1984549 ]\n",
      " [-3.7682695   3.2374845 ]\n",
      " [ 3.4261763  -2.69412   ]\n",
      " [ 0.3237146  -0.01299856]\n",
      " [-3.8308527   3.2898254 ]\n",
      " [ 1.0620074  -0.43930337]\n",
      " [-3.6175933   3.1430902 ]\n",
      " [-3.891561    3.3230813 ]\n",
      " [-3.0648363   2.5535321 ]\n",
      " [-3.8015745   3.28287   ]\n",
      " [-3.7784438   3.252183  ]\n",
      " [-2.1347573   1.4826078 ]\n",
      " [-2.8637717   2.3089347 ]\n",
      " [-1.7296667   1.3734921 ]\n",
      " [-3.5964468   3.1131816 ]\n",
      " [-3.7934175   3.2924187 ]\n",
      " [ 3.252363   -2.6009257 ]\n",
      " [-3.819529    3.2960694 ]\n",
      " [-3.6995184   3.200248  ]\n",
      " [ 2.9085534  -2.2675273 ]\n",
      " [ 3.343383   -2.6894133 ]\n",
      " [-2.4859495   1.9671881 ]\n",
      " [-3.7544029   3.1917405 ]\n",
      " [-1.9638355   1.4637899 ]\n",
      " [ 2.7496302  -2.0810018 ]\n",
      " [-3.783539    3.2587824 ]\n",
      " [-3.891256    3.340399  ]\n",
      " [-3.313955    2.825566  ]\n",
      " [-3.8730755   3.3279722 ]\n",
      " [ 3.3774135  -2.68562   ]\n",
      " [-3.719869    3.1856506 ]\n",
      " [-2.7834108   2.134731  ]\n",
      " [-2.7436485   2.09516   ]\n",
      " [-3.8246293   3.2804003 ]\n",
      " [-1.0862901   0.8501069 ]\n",
      " [-3.8237689   3.2874603 ]\n",
      " [-3.8981164   3.3433726 ]\n",
      " [-3.8730483   3.3252535 ]\n",
      " [-3.8134594   3.2735515 ]\n",
      " [-3.847599    3.3092563 ]\n",
      " [-3.7811263   3.2621524 ]\n",
      " [-3.767886    3.2681878 ]\n",
      " [-3.7049458   3.1733677 ]\n",
      " [-1.7895879   1.4065276 ]\n",
      " [ 3.1227205  -2.4513402 ]\n",
      " [-3.0412714   2.4855804 ]\n",
      " [ 2.314875   -1.732647  ]\n",
      " [-3.57703     3.0918274 ]\n",
      " [ 1.4582671  -0.8639682 ]\n",
      " [-3.4612567   2.9566371 ]\n",
      " [-1.7869271   1.3566837 ]\n",
      " [-3.8379102   3.3205411 ]\n",
      " [ 3.0263832  -2.5654843 ]\n",
      " [-3.1955445   2.6699982 ]\n",
      " [-3.309289    2.803004  ]\n",
      " [-3.828829    3.2859046 ]\n",
      " [-3.8769393   3.334608  ]\n",
      " [-3.7874649   3.280407  ]\n",
      " [-3.3704414   2.8744934 ]\n",
      " [-3.8634677   3.298705  ]\n",
      " [-3.8480132   3.2903495 ]\n",
      " [-3.8029175   3.281534  ]\n",
      " [ 2.4118109  -1.915826  ]\n",
      " [ 3.1778443  -2.547927  ]\n",
      " [-2.7127242   2.063575  ]\n",
      " [ 1.8072292  -1.0693195 ]\n",
      " [ 3.1399865  -2.6091015 ]\n",
      " [-3.8243134   3.2666106 ]\n",
      " [-3.8490984   3.324464  ]\n",
      " [-3.8146923   3.2713559 ]\n",
      " [ 0.45437267 -0.11738434]\n",
      " [-3.7636828   3.2364807 ]\n",
      " [-3.6544487   3.1292746 ]\n",
      " [-3.789891    3.24748   ]\n",
      " [-3.422739    2.9367676 ]\n",
      " [-3.2078285   2.6478698 ]\n",
      " [-2.924447    2.3298209 ]\n",
      " [-3.484195    2.9496307 ]\n",
      " [ 3.1912372  -2.5664043 ]\n",
      " [ 2.625943   -1.9062456 ]\n",
      " [-3.7759418   3.2429478 ]\n",
      " [ 3.0905268  -2.5503142 ]\n",
      " [-3.855203    3.3138325 ]\n",
      " [-3.8647177   3.2934334 ]\n",
      " [-3.8498313   3.302696  ]\n",
      " [-3.862798    3.3089628 ]\n",
      " [-3.796995    3.240904  ]\n",
      " [-3.7394931   3.1944332 ]\n",
      " [-3.6461904   3.1598587 ]\n",
      " [-3.7071095   3.1973295 ]\n",
      " [ 2.954382   -2.2259107 ]\n",
      " [-3.3837013   2.8895152 ]\n",
      " [-3.3086455   2.740649  ]\n",
      " [-2.8841875   2.3612812 ]\n",
      " [ 2.928032   -2.441895  ]\n",
      " [ 1.1096314  -0.6793123 ]\n",
      " [-3.822258    3.289819  ]\n",
      " [-3.884533    3.3412817 ]\n",
      " [-1.6757637   1.3715719 ]\n",
      " [-3.8325713   3.2882934 ]\n",
      " [ 2.3021526  -1.6258729 ]\n",
      " [ 0.920065   -0.4273412 ]\n",
      " [ 3.1287982  -2.5869749 ]\n",
      " [-3.8630955   3.3161623 ]\n",
      " [-3.693013    3.1801293 ]\n",
      " [-3.846808    3.3089468 ]\n",
      " [ 2.6480162  -2.030048  ]\n",
      " [ 3.0005646  -2.472175  ]\n",
      " [-2.0157192   1.6063143 ]\n",
      " [-3.884917    3.3383334 ]\n",
      " [ 2.9652324  -2.4619198 ]\n",
      " [-3.7824118   3.2423155 ]\n",
      " [-3.8454626   3.3099535 ]\n",
      " [-3.63719     3.151339  ]\n",
      " [ 2.8311105  -2.1789207 ]\n",
      " [-3.8715794   3.3313496 ]\n",
      " [-3.8696442   3.3018532 ]\n",
      " [ 3.2989173  -2.7199655 ]\n",
      " [-3.8760433   3.3242197 ]\n",
      " [ 3.0052617  -2.4125404 ]\n",
      " [-3.6200004   3.119573  ]\n",
      " [-3.7750132   3.2252367 ]\n",
      " [-3.8917053   3.3380704 ]\n",
      " [ 2.877444   -2.2227178 ]\n",
      " [ 3.166244   -2.6448836 ]\n",
      " [-3.895907    3.3303306 ]\n",
      " [ 1.4801992  -0.8892947 ]\n",
      " [-1.834564    1.3290238 ]\n",
      " [-3.8672862   3.3216274 ]\n",
      " [ 3.2576222  -2.5625317 ]\n",
      " [ 3.2864177  -2.6760933 ]\n",
      " [ 3.1294053  -2.369837  ]\n",
      " [ 3.3294961  -2.7625415 ]\n",
      " [ 3.6251547  -2.9322245 ]\n",
      " [-3.664746    3.1131403 ]\n",
      " [-2.3307252   1.7857372 ]\n",
      " [-3.8856857   3.331899  ]\n",
      " [-3.5751512   3.0698729 ]\n",
      " [-3.9103      3.3527896 ]\n",
      " [-3.7137108   3.190625  ]\n",
      " [-3.3868713   2.8778226 ]\n",
      " [-3.871644    3.3133843 ]\n",
      " [-3.894391    3.3413827 ]\n",
      " [-3.7008674   3.1578329 ]\n",
      " [-3.4449985   2.9356177 ]\n",
      " [-3.8669918   3.316267  ]\n",
      " [-3.8550775   3.3183126 ]\n",
      " [-3.7308776   3.2008464 ]\n",
      " [-3.8986871   3.3385367 ]\n",
      " [-1.5963193   1.1030227 ]\n",
      " [-3.2356327   2.7401614 ]\n",
      " [-3.8526888   3.3116844 ]\n",
      " [-3.903883    3.3417115 ]\n",
      " [ 2.5306275  -1.7505118 ]\n",
      " [ 3.1278126  -2.577672  ]\n",
      " [-3.8243535   3.28088   ]\n",
      " [-3.8934753   3.3452187 ]\n",
      " [-3.8745894   3.326576  ]\n",
      " [-3.8908808   3.3480067 ]\n",
      " [-3.6987462   3.1977475 ]\n",
      " [-3.8386302   3.2902374 ]\n",
      " [ 2.743676   -2.1372373 ]\n",
      " [-3.84666     3.2813137 ]\n",
      " [-3.4433577   2.9283066 ]\n",
      " [-3.628515    3.088961  ]\n",
      " [ 3.183777   -2.4861925 ]\n",
      " [ 2.9838767  -2.3646648 ]\n",
      " [-3.8441932   3.3281155 ]\n",
      " [-3.437862    2.8813288 ]\n",
      " [-3.6639035   3.1618922 ]\n",
      " [-3.870899    3.3067007 ]\n",
      " [ 1.8239826  -1.2963903 ]\n",
      " [-3.7466984   3.2342572 ]\n",
      " [-3.889701    3.3271053 ]\n",
      " [ 2.5321646  -1.8407015 ]\n",
      " [-3.6773322   3.15473   ]\n",
      " [-3.8045046   3.2531033 ]\n",
      " [-3.8562973   3.2975247 ]\n",
      " [-3.4449084   2.9177063 ]\n",
      " [ 2.660755   -2.113964  ]\n",
      " [ 2.6719966  -2.1178675 ]\n",
      " [ 2.6761992  -2.2566597 ]\n",
      " [-3.6577885   3.11422   ]\n",
      " [-3.912389    3.3420212 ]\n",
      " [-3.253733    2.7894804 ]\n",
      " [ 3.1421597  -2.607938  ]\n",
      " [ 3.2465456  -2.6357238 ]\n",
      " [-1.0027843   1.0960662 ]\n",
      " [ 2.8122785  -2.2016108 ]\n",
      " [-3.819536    3.2996027 ]\n",
      " [-3.8775058   3.3396237 ]\n",
      " [-3.102541    2.5470994 ]\n",
      " [-3.867863    3.314534  ]\n",
      " [ 3.0329726  -2.3835511 ]\n",
      " [-3.887685    3.3279474 ]\n",
      " [-3.688281    3.1665368 ]\n",
      " [ 2.413495   -1.8418458 ]\n",
      " [-3.4915774   3.018445  ]\n",
      " [-1.5851095   1.1642407 ]\n",
      " [-3.8864028   3.335452  ]\n",
      " [ 2.79159    -2.3009262 ]\n",
      " [-3.881155    3.3262584 ]\n",
      " [-3.7535553   3.2288425 ]\n",
      " [-3.3707492   2.7932851 ]\n",
      " [-3.7573938   3.2187216 ]\n",
      " [-3.838806    3.2792418 ]\n",
      " [-3.7479389   3.2437828 ]\n",
      " [-3.8819978   3.3237028 ]\n",
      " [-2.3801768   1.7746781 ]\n",
      " [-3.3831708   2.8957329 ]\n",
      " [-3.8754857   3.312604  ]\n",
      " [ 3.5189607  -2.8138793 ]\n",
      " [-3.8617785   3.3140218 ]\n",
      " [-2.4547207   1.8770162 ]\n",
      " [ 3.007265   -2.5230944 ]\n",
      " [-3.095615    2.5442548 ]\n",
      " [-3.8678346   3.3218153 ]\n",
      " [ 1.2387398  -0.73235506]\n",
      " [-3.5237455   2.9696102 ]] [1 0 0 1 0 1 0 1 1 1 1 0 0 1 1 1 1 0 1 0 0 1 0 1 1 1 0 1 1 1 0 1 1 1 1 0 0\n",
      " 0 1 1 0 1 0 0 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1 0 1 1 1 1 1\n",
      " 1 1 0 1 1 1 0 1 1 0 1 0 1 0 1 1 0 1 1 0 1 1 0 1 1 1 1 1 1 1 0 1 1 0 0 1 1\n",
      " 1 1 1 0 0 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 0 1 0 1 1 0 0 1 0 1 0 0 1 0 0 1 1\n",
      " 1 1 0 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 0 1 0 0 1 1 1 0 1 1 0 1 1 0 0 1 1 0\n",
      " 1 0 1 0 1 1 0 1 1 0 1 1 0 1 1 1 0 1 1 1 0 1 1 1 0 0 1 1 0 1 1 1 1 0 1 1 1\n",
      " 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 0 1 0 1 1 1 1 1 0 1 1 1 0 1 0 1 0 1 1 1\n",
      " 0 1 0 1 1 0 1 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1 1 0 0 1 1 1 1 1 1 0 1 1 1 0\n",
      " 0 0 1 1 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 0 1 1 0 0 0 0 0 1 0 1 0 1 1 1 1 1 0\n",
      " 1 1 1 1 0 0 1 1 1 0 0 1 1 1 1 0 1 0 1 0 1 0 0 1 1 1 1 0 1 1 0 1 1 0 1 0 0\n",
      " 1 1 1 1 0 0 0 0 1 1 1 1 0 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 0\n",
      " 1]\n"
     ]
    }
   ],
   "source": [
    "predictions = trainer.predict(tokenized_datasets[\"validation\"])\n",
    "print(predictions.predictions.shape, predictions.label_ids.shape)\n",
    "print(predictions.predictions, predictions.label_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cc5ba124-a1e6-4578-8dbe-02351282184b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "preds = np.argmax(predictions.predictions, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f7323661-4b25-4fbc-85d2-bddaf95d8500",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.8529411764705882, 'f1': 0.8958333333333334}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import evaluate\n",
    "metric = evaluate.load(\"glue\", \"mrpc\")\n",
    "metric.compute(predictions=preds, references=predictions.label_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cb3ef1fa-5d22-40b4-af2c-bb39745c8171",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_preds):\n",
    "    metric = evaluate.load(\"glue\", \"mrpc\")\n",
    "    logits, lables = eval_preds\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references= lables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "846a76f3-2e43-41d6-abb2-bd991d8bc051",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\Lib\\site-packages\\transformers\\training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\"test-trainer\", evaluation_strategy = \"epoch\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=2)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model,\n",
    "    training_args,\n",
    "    train_dataset = tokenized_datasets[\"train\"],\n",
    "    eval_dataset = tokenized_datasets[\"validation\"],\n",
    "    data_collator = data_collator,\n",
    "    tokenizer = tokenizer,\n",
    "    compute_metrics = compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "719dcb60-9e3e-40c8-a036-c2804c8e713b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1377' max='1377' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1377/1377 01:56, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.465118</td>\n",
       "      <td>0.779412</td>\n",
       "      <td>0.859813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.531100</td>\n",
       "      <td>0.466259</td>\n",
       "      <td>0.848039</td>\n",
       "      <td>0.893836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.334700</td>\n",
       "      <td>0.614068</td>\n",
       "      <td>0.852941</td>\n",
       "      <td>0.897260</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1377, training_loss=0.37226222196868475, metrics={'train_runtime': 116.4343, 'train_samples_per_second': 94.508, 'train_steps_per_second': 11.826, 'total_flos': 405114969714960.0, 'train_loss': 0.37226222196868475, 'epoch': 3.0})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c40f61c7-3d80-47e0-a3a1-77ae2e263198",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
